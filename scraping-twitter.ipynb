{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/scraping-twitter?scriptVersionId=121835345\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"48952906","metadata":{"papermill":{"duration":0.002745,"end_time":"2023-03-12T06:20:21.63765","exception":false,"start_time":"2023-03-12T06:20:21.634905","status":"completed"},"tags":[]},"source":["# Why Scrape Twitter?\n","\n","- [Twitter](https://twitter.com/Twitter) is a major announcement hub where people and companies publish their announcements. This is a great opportunity to use Twitter to follow industry trends. For example, stock market or crypto market targets could be scraped to predict the future price of a stock or crypto.\n","\n","- Twitter is also a great source of data for sentiment analysis. You can use Twitter to find out what people think about a certain topic or brand. This is useful for market research, product development, and brand awareness.\n","\n","- So, if we can scrape Twitter data with Python we can have access to this valuable public information for free!"]},{"cell_type":"markdown","id":"d2dc4cba","metadata":{"papermill":{"duration":0.001291,"end_time":"2023-03-12T06:20:21.640834","exception":false,"start_time":"2023-03-12T06:20:21.639543","status":"completed"},"tags":[]},"source":["# Setup Wizard\n","\n","- We'll approach Twitter scraping in three ways:\n","\n","  - We'll be using [browser automation toolkit Playwright](https://scrapfly.io/blog/web-scraping-with-playwright-and-python/)\n","    - This is the easiest way to scrape Twitter as we are using real web browser, so all we have to do is navigate to url, wait for page to load and get the results.\n","\n","  - We'll also take a look at reverse engineering Twitter's hidden API.\n","This will be a bit harder but these type of scrapers will be much faster than the browser ones. For this we'll be using [httpx](https://pypi.org/project/httpx/).\n","\n","  - For ScrapFly users we'll also take a look at ScrapFly SDK which makes the above methods even easier.\n","\n","\n","- We'll be working with both JSON and HTML response data. So, we'll be using [parsel](https://pypi.org/project/parsel/) to parse HTML and [jamespath for JSON](https://scrapfly.io/blog/parse-json-jmespath-python/)."]},{"cell_type":"markdown","id":"89b95b1b","metadata":{"papermill":{"duration":0.001256,"end_time":"2023-03-12T06:20:21.643575","exception":false,"start_time":"2023-03-12T06:20:21.642319","status":"completed"},"tags":[]},"source":["#### All of these libraries are available for free and can be installed via the pip install terminal command:\n","\n","   $ pip install httpx playwright parsel jmespath scrapfly-sdk"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":10.683891,"end_time":"2023-03-12T06:20:22.268336","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-03-12T06:20:11.584445","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}